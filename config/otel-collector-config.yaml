# OpenTelemetry Collector Configuration for Spark Application

receivers:
  # OTLP receiver for traces, metrics, and logs
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
        
  # Prometheus receiver for scraping metrics
  prometheus:
    config:
      scrape_configs:
        - job_name: 'spark-metrics'
          scrape_interval: 15s
          static_configs:
            - targets: ['pushgateway:9091']
              labels:
                service: 'spark-app'
                
        - job_name: 'otel-collector'
          scrape_interval: 10s
          static_configs:
            - targets: ['localhost:8888']
              
  # Host metrics receiver
  hostmetrics:
    collection_interval: 10s
    scrapers:
      cpu:
      disk:
      filesystem:
      load:
      memory:
      network:
      paging:
      process:
        include:
          names: ["java", "python"]
          
  # Kafka receiver for logs
  kafka:
    protocol_version: 2.0.0
    brokers:
      - kafka:9092
    topic: spark-logs
    encoding: utf-8
    group_id: otel-collector
    client_id: otel-collector-client

processors:
  # Batch processor to batch telemetry data
  batch:
    timeout: 10s
    send_batch_size: 1024
    
  # Memory limiter to prevent OOM
  memory_limiter:
    check_interval: 1s
    limit_mib: 1024
    spike_limit_mib: 256
    
  # Resource processor to add metadata
  resource:
    attributes:
      - key: service.name
        value: spark-production-app
        action: insert
      - key: environment
        from_attribute: ENVIRONMENT
        action: insert
      - key: cluster.name
        value: spark-cluster
        action: insert
        
  # Attributes processor for data enrichment
  attributes:
    actions:
      - key: spark.app.id
        from_attribute: spark_app_id
        action: insert
      - key: spark.app.name
        from_attribute: spark_app_name
        action: insert
        
  # Transform processor for Spark-specific metrics
  transform/spark_metrics:
    metric_statements:
      - context: metric
        statements:
          - set(description, "Spark application metrics") where name == "spark.*"
          
  # Filter processor to remove sensitive data
  filter:
    error_mode: ignore
    logs:
      log_record:
        - 'IsMatch(body, ".*password.*")'
        - 'IsMatch(body, ".*secret.*")'
        - 'IsMatch(body, ".*token.*")'

exporters:
  # Prometheus exporter for metrics
  prometheusremotewrite:
    endpoint: "http://prometheus:9090/api/v1/write"
    tls:
      insecure: true
    resource_to_telemetry_conversion:
      enabled: true
      
  # Jaeger exporter for traces
  otlp/jaeger:
    endpoint: jaeger:4317
    tls:
      insecure: true
      
  # Elasticsearch exporter for logs
  elasticsearch:
    endpoints: ["http://elasticsearch:9200"]
    logs_index: spark-logs
    traces_index: spark-traces
    metrics_index: spark-metrics
    
  # Debug exporter for troubleshooting
  debug:
    verbosity: detailed
    sampling_initial: 5
    sampling_thereafter: 200
    
  # File exporter for backup
  file:
    path: /var/log/otel/telemetry.json
    rotation:
      max_megabytes: 100
      max_days: 7
      max_backups: 3

extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133
    
  # Performance profiler
  pprof:
    endpoint: 0.0.0.0:1777
    
  # zPages for debugging
  zpages:
    endpoint: 0.0.0.0:55679
    
  # Memory ballast extension has been removed in newer versions

service:
  extensions: [health_check, pprof, zpages]
  
  pipelines:
    # Traces pipeline
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch, resource, attributes]
      exporters: [otlp/jaeger, file]
      
    # Metrics pipeline
    metrics:
      receivers: [otlp, prometheus, hostmetrics]
      processors: [memory_limiter, batch, resource, transform/spark_metrics]
      exporters: [prometheusremotewrite, file]
      
    # Logs pipeline
    logs:
      receivers: [otlp, kafka]
      processors: [memory_limiter, batch, resource, filter]
      exporters: [elasticsearch, file]
      
  telemetry:
    logs:
      level: info
      initial_fields:
        service: otel-collector
    metrics:
      level: detailed
      address: 0.0.0.0:8888