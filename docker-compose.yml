version: '3.8'

services:
  # === Spark Services ===
  spark-master:
    build: .
    container_name: spark-master
    hostname: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      # AWS Credentials
      - AWS_PROFILE=${AWS_PROFILE:-toy-root}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION:-us-east-1}
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
      - ./checkpoint:/app/checkpoint
      - ~/.aws:/home/spark/.aws:ro  # Mount AWS credentials
    networks:
      - spark-network

  spark-worker-1:
    build: .
    container_name: spark-worker-1
    hostname: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=8g
      - SPARK_WORKER_WEBUI_PORT=8081
      # AWS Credentials
      - AWS_PROFILE=${AWS_PROFILE:-toy-root}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION:-us-east-1}
    ports:
      - "8081:8081"
    depends_on:
      - spark-master
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ~/.aws:/home/spark/.aws:ro  # Mount AWS credentials
    networks:
      - spark-network

  spark-worker-2:
    build: .
    container_name: spark-worker-2
    hostname: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=8g
      - SPARK_WORKER_WEBUI_PORT=8082
      # AWS Credentials
      - AWS_PROFILE=${AWS_PROFILE:-toy-root}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION:-us-east-1}
    ports:
      - "8082:8082"
    depends_on:
      - spark-master
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ~/.aws:/home/spark/.aws:ro  # Mount AWS credentials
    networks:
      - spark-network

  # === Data Infrastructure ===
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    networks:
      - spark-network

  # === Development Tools ===
  spark-history:
    build: .
    container_name: spark-history
    hostname: spark-history
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/app/logs/spark-events
      # AWS Credentials
      - AWS_PROFILE=${AWS_PROFILE:-toy-root}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION:-us-east-1}
    ports:
      - "18080:18080"
    volumes:
      - ./logs:/app/logs
      - ~/.aws:/home/spark/.aws:ro  # Mount AWS credentials
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.history.HistoryServer"]
    networks:
      - spark-network

  jupyter:
    build: .
    container_name: jupyter
    ports:
      - "8888:8888"
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - JUPYTER_ENABLE_LAB=yes
      # AWS Credentials
      - AWS_PROFILE=${AWS_PROFILE:-toy-root}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION:-us-east-1}
    volumes:
      - ./notebooks:/app/notebooks
      - ./data:/app/data
      - ./src:/app/src
      - ~/.aws:/home/spark/.aws:ro  # Mount AWS credentials
    command: ["jupyter", "lab", "--ip=0.0.0.0", "--port=8888", "--no-browser", "--allow-root", "--NotebookApp.token="]
    working_dir: /app
    networks:
      - spark-network

networks:
  spark-network:
    driver: bridge